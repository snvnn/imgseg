{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaxq33gFMNb7"
   },
   "source": [
    "# 동물 이미지 Segmentation 챌린지\n",
    "\n",
    "> 오픈소스 AI 응용 (2025-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5Ok2P21tXNE"
   },
   "outputs": [],
   "source": [
    "#==========================================================\n",
    "#  Copyright (c) 2025 Boeun Kim / Dankook University\n",
    "#  All rights reserved.\n",
    "#\n",
    "#  File: 2025_pet_segmentation_base_code.ipynb\n",
    "#  Description: This file was created for the Open Source AI\n",
    "#               Applications course at Dankook University.\n",
    "#\n",
    "#  Author: Boeun Kim\n",
    "#  Date: 2025-10-30\n",
    "#\n",
    "#  License: MIT License\n",
    "#\n",
    "#  Note: This project uses a modified version of the\n",
    "#        Oxford-IIIT Pet Dataset. The original dataset\n",
    "#        is subject to its own license:\n",
    "#        \"Oxford-IIIT Pet Dataset\" © University of Oxford\n",
    "#=========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVAUhu6SWQv5"
   },
   "source": [
    "# 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gx_BjGDZUQkf"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "# 구글 드라이브의 데이터셋 zip파일을 임시 폴더로 복사 (데이터셋 로드를 빠르게 해줌)\n",
    "#!cp \"/content/drive/MyDrive/Colab Notebooks/project/dataset/train.zip\" /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seAMHl9zUnw_"
   },
   "outputs": [],
   "source": [
    "# 압축 해제\n",
    "#!unzip /content/train.zip -d /content/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Arjp6Q7ZU3YF"
   },
   "outputs": [],
   "source": [
    "# 압축이 잘 해제되었는지 확인\n",
    "#!ls /content/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZP_ilETWVEY"
   },
   "source": [
    "# Configuration (하이퍼파라미터, 경로 등 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUxRM39ZVU8U"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# 고정되어야 하는 것. 바꾸지 말 것\n",
    "IMAGE_SIZE = (256, 256)\n",
    "N_CLASSES = 3  # trimap은 각 픽셀이 배경, 가장자리, 동물부분 이렇게 3개 중 하나의 클래스로 배정된 것\n",
    "\n",
    "# Seeds\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Device settings\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Data paths\n",
    "IMAGE_PATH = 'train/images'\n",
    "MAP_PATH = 'train/trimaps'\n",
    "\n",
    "# Learning parameters\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 1000\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_PATH = 'train/output'\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "  os.mkdir(OUTPUT_PATH)\n",
    "MODEL_PATH = os.path.join(OUTPUT_PATH, 'model_weight.pth')\n",
    "HISTORY_PATH = os.path.join(OUTPUT_PATH, 'history.pickle')\n",
    "HISTORY_PLOT_PATH = os.path.join(OUTPUT_PATH, 'history.png')  # 드라이브에 저장하고 싶다면 경로를 변경해야 함\n",
    "HISTORY_LOGPLOT_PATH = os.path.join(OUTPUT_PATH, 'loghistory.png') \n",
    "PRED_PLOT_PATH = os.path.join(OUTPUT_PATH, 'pred.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfwEmoQ_ZDMm"
   },
   "source": [
    "# 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcgWyXF0Y6TU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class TrimapsDataset(Dataset):\n",
    "  def __init__(self, img_path, map_path='', test=False):\n",
    "    super().__init__()\n",
    "\n",
    "    self.istest=test\n",
    "\n",
    "    # 이미지 경로의 리스트 생성\n",
    "    self.img_path_list = sorted([\n",
    "        os.path.join(img_path, name)\n",
    "        for name in os.listdir(img_path)\n",
    "        if name.endswith('.jpg')\n",
    "    ])\n",
    "\n",
    "    # 맵 경로의 리스트 생성, train 데이터에만 gt 맵 존재\n",
    "    if not self.istest:\n",
    "      self.map_path_list = sorted([\n",
    "          os.path.join(map_path, name)\n",
    "          for name in os.listdir(map_path)\n",
    "          if name.endswith('.png')\n",
    "      ])\n",
    "\n",
    "    # 이미지 transform 정의 (리사이즈, 텐서로 변환)\n",
    "    self.transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.img_path_list)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    image_path = self.img_path_list[idx]\n",
    "    # 데이터 id 추출. 결과제출시 필요\n",
    "    data_id = image_path.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "\n",
    "    # 이미지 열어 RGB로 변경\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    # 이미지 transform 적용\n",
    "    image = self.transform(image)\n",
    "\n",
    "    # train 데이터에만 gt 맵 존재\n",
    "    if not self.istest:\n",
    "      map_path = self.map_path_list[idx]\n",
    "      # 맵 열어 grayscale 로 변경\n",
    "      map = Image.open(map_path).convert('L')\n",
    "      # 맵 transform 적용\n",
    "      map = self.transform(map)\n",
    "      # map은 0과 1 사이의 값으로 되어있으므로 255를 곱해 정수로 만듦\n",
    "      map = map * 255\n",
    "      map = map.squeeze().to(torch.int64)\n",
    "      # GT 라벨은 1, 2, 3인데 분류 편의성을 위해 0, 1, 2로 변경\n",
    "      map -= 1\n",
    "      return image, map\n",
    "\n",
    "    return image, data_id  # 채점을 위해 테스트 모드에서는 데이터 ID와 함께 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiHbb2tBjZT8"
   },
   "source": [
    "# 모델 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeFCgMWvDGOr"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, img_size):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(16, out_channel, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoixYt4DkSvD"
   },
   "source": [
    "# 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7jGABwlkcQa"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def train(model, train_loader):\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  loss_fn = CrossEntropyLoss()\n",
    "  optim = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "  history = {'train_loss': []}\n",
    "  start_time = time.time()\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    print('EPOCH: {}'.format(epoch))\n",
    "    train_loss = 0.\n",
    "\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "      images, targets = images.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "      pred = model(images)\n",
    "      loss = loss_fn(pred, targets)\n",
    "\n",
    "      optim.zero_grad()\n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "\n",
    "      train_loss += loss*len(images)\n",
    "\n",
    "    avg_train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('TRAIN LOSS: {}'.format(avg_train_loss))\n",
    "    history['train_loss'].append(avg_train_loss.cpu().detach().numpy())\n",
    "\n",
    "  # 학습 시간 측정\n",
    "  end_time = time.time() - start_time\n",
    "  print('Total time: {}s'.format(end_time))\n",
    "\n",
    "  # 학습된 모델 파라미터 저장\n",
    "  torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "  # Loss 그래프를 만들기 위한 히스토리 저장\n",
    "  with open(HISTORY_PATH, 'wb', ) as f:\n",
    "      pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7_BY_l4qi_8"
   },
   "source": [
    "# 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUgqWcoSqr3C"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = TrimapsDataset(IMAGE_PATH, MAP_PATH, test=False)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = BaseModel(3, N_CLASSES, IMAGE_SIZE)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# train 함수 실행\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-28N7xkFOK9x"
   },
   "source": [
    "# 평가함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVC4S8SfOSIA"
   },
   "outputs": [],
   "source": [
    "# 평가 메트릭인 mIoU 계산 과정\n",
    "def compute_iou_tensor(pred_map, target_map):\n",
    "    intersection = (pred_map & target_map).sum(dim=(1, 2)).float()\n",
    "    union = (pred_map | target_map).sum(dim=(1, 2)).float()\n",
    "    iou = torch.where(union > 0, intersection / union, torch.ones_like(union))\n",
    "    return iou\n",
    "\n",
    "def eval(model, train_loader):\n",
    "    model.eval()\n",
    "    total_iou = torch.zeros(N_CLASSES).to(DEVICE)\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            images, targets = images.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # 클래스별 mIoU 계산\n",
    "            for cls in range(N_CLASSES):\n",
    "                pred_map = (preds == cls)\n",
    "                target_map = (targets == cls)\n",
    "\n",
    "                iou = compute_iou_tensor(pred_map, target_map)\n",
    "                total_iou[cls] += iou.sum()\n",
    "\n",
    "            total_samples += images.size(0)\n",
    "\n",
    "    mean_iou_per_class = total_iou / total_samples\n",
    "    mIoU = mean_iou_per_class.mean().item()\n",
    "\n",
    "    print(f\"[EVAL] mIoU: {mIoU:.4f}\")\n",
    "    return mIoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzTDP_ptOV2X"
   },
   "source": [
    "# 학습 데이터의 평가 결과 확인\n",
    "챌린지 결과는 테스트 데이터에서 같은 방법으로 평가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3CAQrcvOi29"
   },
   "outputs": [],
   "source": [
    "model = BaseModel(3, N_CLASSES, IMAGE_SIZE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "eval(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsfNXvcJokp0"
   },
   "source": [
    "#결과 제출\n",
    "테스트 데이터에 대해 모델 수행 후 결과 파일 생성.\n",
    "\n",
    "드라이브에 저장된 submission.csv 파일을 챌린지 사이트에 제출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vv5TkY1ousl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 테스트 데이터 다운로드 & unzip\n",
    "#drive.mount('/content/drive')\n",
    "#!cp \"/content/drive/MyDrive/Colab Notebooks/project/dataset/test.zip\" /content/\n",
    "#!unzip /content/test.zip -d /content/testset\n",
    "\n",
    "# RLE (Run Length Encoding) 함수. 파일 제출 형식을 맞추기 위해 필요. 수정하지 말 것\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def get_rle(model, test_loader, save_path):\n",
    "  model.eval()\n",
    "\n",
    "  image_ids = []\n",
    "  image_paths = []\n",
    "  class_ids = []\n",
    "  rles = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, (images, data_id) in enumerate(test_loader):\n",
    "      images = images.to(DEVICE)\n",
    "\n",
    "      outputs = model(images)\n",
    "      preds = torch.argmax(outputs, dim=1)\n",
    "      preds = preds.cpu().numpy()  # numpy로 변환\n",
    "\n",
    "      for b in range(preds.shape[0]):\n",
    "          pred_mask = preds[b] + 1  # 모델에서 편의를 위해 0, 1, 2로 변환했었기 때문에 되돌리기 위해 +1\n",
    "          image_id = 'TEST_'+data_id[b]\n",
    "\n",
    "          # 클래스별 RLE 인코딩 (1=foreground, 2=border, 3=background)\n",
    "          for class_id in [1, 2, 3]:\n",
    "              mask = (pred_mask == class_id).astype(np.uint8)\n",
    "              rle = rle_encode(mask) if mask.sum() > 0 else ''\n",
    "\n",
    "              image_ids.append(image_id)\n",
    "              class_ids.append(class_id)\n",
    "              rles.append(rle)\n",
    "\n",
    "    # DataFrame 저장\n",
    "    df = pd.DataFrame({\n",
    "        'image_id': image_ids,\n",
    "        'class_id': class_ids,\n",
    "        'rle': rles\n",
    "    })\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"RLE CSV file saved : {save_path}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbDnqefkoyaF"
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "TEST_PATH = 'images'\n",
    "SUBMISSION_FILE_PATH = 'submission/submission.csv'\n",
    "\n",
    "test_set = TrimapsDataset(TEST_PATH, '', test=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = BaseModel(3, N_CLASSES, IMAGE_SIZE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "get_rle(model, test_loader, SUBMISSION_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM6p5H1AzuCk"
   },
   "source": [
    "# [참고 활용] Loss 그래프 확인 및 Trimap 도출 결과 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNGF23Pi0Esa"
   },
   "source": [
    "Loss 그래프 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Jk7j1D10Jwy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 저장한 Loss 히스토리 로드\n",
    "with open(HISTORY_PATH, 'rb') as f:\n",
    "    model_history = pickle.load(f)\n",
    "\n",
    "# 그래프 만들어 이미지로 저장\n",
    "plt.figure()\n",
    "plt.plot(model_history['train_loss'], label='Train loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(HISTORY_PLOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로그 스케일 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# 저장한 Loss 히스토리 로드\n",
    "with open(HISTORY_PATH, 'rb') as f:\n",
    "    model_history = pickle.load(f)\n",
    "\n",
    "# 그래프 만들어 이미지로 저장\n",
    "plt.figure()\n",
    "plt.plot(model_history['train_loss'], label='Train loss')\n",
    "\n",
    "# 로그 스케일 설정\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training Loss (Log Scale)')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.savefig(HISTORY_LOGPLOT_PATH, dpi=200, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuQkVJDg0xNa"
   },
   "source": [
    "Trimap 도출 결과 확인\n",
    "\n",
    "본 코드는 학습에 사용한 이미지를 랜덤하게 선택해 확인해 보는 것으로, 테스트 이미지에 좋은 성능을 보이는지와는 일치하지 않을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8aJIGEw1Z1R"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 저장된 모델 weight 로드\n",
    "model = BaseModel(3, N_CLASSES, IMAGE_SIZE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# 이미지 경로의 리스트 생성\n",
    "img_path_list = sorted([\n",
    "    os.path.join(IMAGE_PATH, name)\n",
    "    for name in os.listdir(IMAGE_PATH)\n",
    "    if name.endswith('.jpg')\n",
    "])\n",
    "\n",
    "# 맵 경로의 리스트 생성\n",
    "map_path_list = sorted([\n",
    "    os.path.join(MAP_PATH, name)\n",
    "    for name in os.listdir(MAP_PATH)\n",
    "    if name.endswith('.png')\n",
    "])\n",
    "\n",
    "# 랜덤한 세개의 인덱스 추출 후 이미지와 맵의 경로 저장\n",
    "indices = random.sample(range(len(img_path_list) - 1), 3)\n",
    "image_map_paths = {img_path_list[idx]: map_path_list[idx] for idx in indices}\n",
    "\n",
    "# 이미지 transform 정의. 데이터셋 클래스와 같아야 함\n",
    "transform = transforms.Compose([\n",
    "transforms.Resize(IMAGE_SIZE),\n",
    "transforms.ToTensor()\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "  figure, ax = plt.subplots(3, 3, figsize=(12, 12), subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "  for i, (image, map) in enumerate(image_map_paths.items()):\n",
    "    # 이미지 로드 후 transform. 데이터셋 클래스와 같은 작업\n",
    "    image = Image.open(image).convert('RGB')\n",
    "    image = transform(image).to(DEVICE)\n",
    "    image = torch.unsqueeze(image, dim=0) # 배치 dimension 추가\n",
    "\n",
    "    # 모델 통과 후 예측 맵 생성\n",
    "    pred = model(image).squeeze()\n",
    "    pred = torch.argmax(pred, dim=0) # logit이 가장 큰 class 선택\n",
    "    pred = pred.cpu().numpy()\n",
    "    pred = pred * 255   # 이미지로 표시하기 위해 255 곱함\n",
    "\n",
    "    # 정답 맵 로드\n",
    "    map = Image.open(map).convert('L')\n",
    "    map = transform(map)\n",
    "    map = torch.squeeze(map, dim=0)\n",
    "    map = map * 255\n",
    "    map -= 1\n",
    "\n",
    "    # 이미지 plot\n",
    "    image = image.squeeze().permute(1, 2, 0).cpu()\n",
    "    ax[i, 0].imshow(image)\n",
    "    ax[i, 1].imshow(map)\n",
    "    ax[i, 2].imshow(pred)\n",
    "\n",
    "  # Save the plot\n",
    "  figure.savefig(PRED_PLOT_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNI5I8vRcQgYQm6SSkJ+WWo",
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1VXClsnnCdNM131HqzHOP4VjIeE6e4e8Q",
     "timestamp": 1762078036850
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
