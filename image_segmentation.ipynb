{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaxq33gFMNb7"
   },
   "source": [
    "# 동물 이미지 Segmentation 챌린지\n",
    "\n",
    "> 오픈소스 AI 응용 (2025-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVAUhu6SWQv5"
   },
   "source": [
    "# 데이터셋 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZP_ilETWVEY"
   },
   "source": [
    "# Configuration (하이퍼파라미터, 경로 등 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUxRM39ZVU8U"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# 고정되어야 하는 것. 바꾸지 말 것\n",
    "IMAGE_SIZE = (256, 256)\n",
    "N_CLASSES = 3  # trimap은 각 픽셀이 배경, 가장자리, 동물부분 이렇게 3개 중 하나의 클래스로 배정된 것\n",
    "\n",
    "# Seeds\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Device settings\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Data paths\n",
    "IMAGE_PATH = 'train/images'\n",
    "MAP_PATH = 'train/trimaps'\n",
    "\n",
    "# Learning parameters\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 20\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_PATH = 'train/output'\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "  os.mkdir(OUTPUT_PATH)\n",
    "MODEL_PATH = os.path.join(OUTPUT_PATH, 'model_weight.pth')\n",
    "HISTORY_PATH = os.path.join(OUTPUT_PATH, 'history.pickle')\n",
    "HISTORY_PLOT_PATH = os.path.join(OUTPUT_PATH, 'history.png')  # 드라이브에 저장하고 싶다면 경로를 변경해야 함\n",
    "HISTORY_LOGPLOT_PATH = os.path.join(OUTPUT_PATH, 'loghistory.png') \n",
    "PRED_PLOT_PATH = os.path.join(OUTPUT_PATH, 'pred.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfwEmoQ_ZDMm"
   },
   "source": [
    "# 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcgWyXF0Y6TU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class TrimapsDataset(Dataset):\n",
    "  def __init__(self, img_path, map_path='', test=False):\n",
    "    super().__init__()\n",
    "\n",
    "    self.istest=test\n",
    "\n",
    "    # 이미지 경로의 리스트 생성\n",
    "    self.img_path_list = sorted([\n",
    "        os.path.join(img_path, name)\n",
    "        for name in os.listdir(img_path)\n",
    "        if name.endswith('.jpg')\n",
    "    ])\n",
    "\n",
    "    # 맵 경로의 리스트 생성, train 데이터에만 gt 맵 존재\n",
    "    if not self.istest:\n",
    "      self.map_path_list = sorted([\n",
    "          os.path.join(map_path, name)\n",
    "          for name in os.listdir(map_path)\n",
    "          if name.endswith('.png')\n",
    "      ])\n",
    "\n",
    "    # 이미지 transform 정의 (리사이즈, 텐서로 변환)\n",
    "    self.transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.img_path_list)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    image_path = self.img_path_list[idx]\n",
    "    # 데이터 id 추출. 결과제출시 필요\n",
    "    data_id = image_path.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "\n",
    "    # 이미지 열어 RGB로 변경\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    # 이미지 transform 적용\n",
    "    image = self.transform(image)\n",
    "\n",
    "    # train 데이터에만 gt 맵 존재\n",
    "    if not self.istest:\n",
    "      map_path = self.map_path_list[idx]\n",
    "      # 맵 열어 grayscale 로 변경\n",
    "      map = Image.open(map_path).convert('L')\n",
    "      # 맵 transform 적용\n",
    "      map = self.transform(map)\n",
    "      # map은 0과 1 사이의 값으로 되어있으므로 255를 곱해 정수로 만듦\n",
    "      map = map * 255\n",
    "      map = map.squeeze().to(torch.int64)\n",
    "      # GT 라벨은 1, 2, 3인데 분류 편의성을 위해 0, 1, 2로 변경\n",
    "      map -= 1\n",
    "      return image, map\n",
    "\n",
    "    return image, data_id  # 채점을 위해 테스트 모드에서는 데이터 ID와 함께 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiHbb2tBjZT8"
   },
   "source": [
    "# 모델 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeFCgMWvDGOr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import Optional\n",
    "\n",
    "def get_norm_layer(num_channels, kind=\"bn\"):\n",
    "    if kind == \"bn\":\n",
    "        return nn.BatchNorm2d(num_channels)\n",
    "    elif kind == \"gn\":\n",
    "        # 채널 수에 따라 그룹 수 자동 조절(8 또는 16 권장)\n",
    "        groups = 16 if num_channels >= 32 else 8\n",
    "        groups = min(groups, num_channels)\n",
    "        return nn.GroupNorm(groups, num_channels)\n",
    "    else:\n",
    "        return nn.Identity()\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, ch, r=8):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch // r, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch // r, ch, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        w = self.fc(self.pool(x))\n",
    "        return x * w\n",
    "\n",
    "class ResidualConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=\"bn\", se=False, drop=0.0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            get_norm_layer(out_ch, norm), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            get_norm_layer(out_ch, norm)\n",
    "        )\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.proj = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "        self.se = SEBlock(out_ch) if se else nn.Identity()\n",
    "        self.drop = nn.Dropout2d(p=drop) if drop > 0 else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        res = self.proj(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.se(x)\n",
    "        x = self.drop(x)\n",
    "        return self.act(x + res)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=\"bn\", se=False, drop=0.0):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.block = ResidualConv(in_ch, out_ch, norm=norm, se=se, drop=drop)\n",
    "    def forward(self, x):\n",
    "        return self.block(self.pool(x))\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    \"\"\"\n",
    "    Skip connection에 사용하는 Attention Gate.\n",
    "    g: decoder feature (업샘플된 feature)\n",
    "    x: encoder에서 온 skip feature\n",
    "    \"\"\"\n",
    "    def __init__(self, F_g, F_x, F_int, norm=\"bn\"):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, bias=False),\n",
    "            get_norm_layer(F_int, norm),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_x, F_int, kernel_size=1, bias=False),\n",
    "            get_norm_layer(F_int, norm),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        # g: upsampled decoder feature, x: encoder skip feature\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "\n",
    "        # 두 feature를 더한 뒤 비선형 변환 → 1채널 마스크\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)  # [B, 1, H, W]\n",
    "\n",
    "        # skip feature에 마스크를 곱해 중요한 위치만 통과\n",
    "        return x * psi\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, norm=\"bn\", se=False, drop=0.0):\n",
    "        super().__init__()\n",
    "        # 업샘플은 bilinear + 1x1로 깔끔하게\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),\n",
    "            nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "        )\n",
    "        # decoder feature(g)와 encoder skip(x)에 대한 attention gate\n",
    "        self.attn = AttentionGate(F_g=out_ch, F_x=out_ch, F_int=out_ch // 2, norm=norm)\n",
    "\n",
    "        # attention으로 필터링된 skip과 concat 후 residual block\n",
    "        self.block = ResidualConv(out_ch*2, out_ch, norm=norm, se=se, drop=drop)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        # decoder feature upsample\n",
    "        x = self.up(x)\n",
    "\n",
    "        # 크기 보정(odd 입력일 때)\n",
    "        if x.shape[-1] != skip.shape[-1] or x.shape[-2] != skip.shape[-2]:\n",
    "            x = nn.functional.pad(\n",
    "                x,\n",
    "                (0, skip.shape[-1] - x.shape[-1], 0, skip.shape[-2] - x.shape[-2])\n",
    "            )\n",
    "\n",
    "        # skip connection에 attention 적용\n",
    "        skip = self.attn(x, skip)\n",
    "\n",
    "        # concat 후 convolution block\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        return self.block(x)\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    \"\"\"가볍게 쓸 수 있는 ASPP(선택). 멀티스케일 컨텍스트 강화.\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, rates=(1, 6, 12, 18), norm=\"bn\"):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1 if r==1 else 3, padding=0 if r==1 else r, dilation=r, bias=False),\n",
    "                get_norm_layer(out_ch, norm),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for r in rates\n",
    "        ])\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(out_ch*len(rates), out_ch, 1, bias=False),\n",
    "            get_norm_layer(out_ch, norm),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        feats = [b(x) for b in self.branches]\n",
    "        x = torch.cat(feats, dim=1)\n",
    "        return self.project(x)\n",
    "\n",
    "class ImprovedUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    - in_channel: 입력 채널(예: RGB=3)\n",
    "    - out_channel: 클래스 수(배경 포함)\n",
    "    - img_size: (H,W) 안 써도 OK, 필요 시 검증용으로 들고만 다님\n",
    "    - norm: 'bn' 또는 'gn'\n",
    "    - use_aspp: 마지막 bottleneck에 ASPP 사용 여부\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, out_channel, img_size: Optional[tuple]=None,\n",
    "                 base_ch=32, norm=\"bn\", se=True, drop=0.1, use_aspp=False):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = ResidualConv(in_channel,  base_ch,      norm=norm, se=se, drop=0.0)\n",
    "        self.enc2 = Down(base_ch,             base_ch*2,    norm=norm, se=se, drop=drop)\n",
    "        self.enc3 = Down(base_ch*2,           base_ch*4,    norm=norm, se=se, drop=drop)\n",
    "        self.enc4 = Down(base_ch*4,           base_ch*8,    norm=norm, se=se, drop=drop)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResidualConv(base_ch*8, base_ch*16, norm=norm, se=se, drop=drop)\n",
    "        self.aspp = ASPP(base_ch*16, base_ch*16, rates=(1, 6, 12, 18), norm=norm) if use_aspp else nn.Identity()\n",
    "\n",
    "        # Decoder\n",
    "        self.up3 = Up(base_ch*16, base_ch*8,  norm=norm, se=se, drop=drop)\n",
    "        self.up2 = Up(base_ch*8,  base_ch*4,  norm=norm, se=se, drop=drop)\n",
    "        self.up1 = Up(base_ch*4,  base_ch*2,  norm=norm, se=se, drop=drop)\n",
    "        self.up0 = Up(base_ch*2,  base_ch,    norm=norm, se=se, drop=0.0)\n",
    "\n",
    "        self.head = nn.Conv2d(base_ch, out_channel, kernel_size=1)\n",
    "\n",
    "        # 간단한 Kaiming init\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "            if getattr(m, \"bias\", None) is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        e1 = self.enc1(x)      # H\n",
    "        e2 = self.enc2(e1)     # H/2\n",
    "        e3 = self.enc3(e2)     # H/4\n",
    "        e4 = self.enc4(e3)     # H/8\n",
    "\n",
    "        # bottleneck (+ optional ASPP)\n",
    "        b  = self.bottleneck(e4)\n",
    "        b  = self.aspp(b)\n",
    "\n",
    "        # decoder with skips\n",
    "        d3 = self.up3(b,  e4)  # H/8\n",
    "        d2 = self.up2(d3, e3)  # H/4\n",
    "        d1 = self.up1(d2, e2)  # H/2\n",
    "        d0 = self.up0(d1, e1)  # H\n",
    "        logits = self.head(d0) # [B, out_channel, H, W]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoixYt4DkSvD"
   },
   "source": [
    "# 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7jGABwlkcQa"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def train(model, train_loader):\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  loss_fn = CrossEntropyLoss()\n",
    "  optim = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "  history = {'train_loss': []}\n",
    "  start_time = time.time()\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    print('EPOCH: {}'.format(epoch))\n",
    "    train_loss = 0.\n",
    "\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "      images, targets = images.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "      pred = model(images)\n",
    "      loss = loss_fn(pred, targets)\n",
    "\n",
    "      optim.zero_grad()\n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "\n",
    "      train_loss += loss*len(images)\n",
    "\n",
    "    avg_train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('TRAIN LOSS: {}'.format(avg_train_loss))\n",
    "    history['train_loss'].append(avg_train_loss.cpu().detach().numpy())\n",
    "\n",
    "  # 학습 시간 측정\n",
    "  end_time = time.time() - start_time\n",
    "  print('Total time: {}s'.format(end_time))\n",
    "  # 학습된 모델 파라미터 저장\n",
    "  torch.save(model.state_dict(), MODEL_PATH)\n",
    "  \n",
    "    # Loss 그래프를 만들기 위한 히스토리 저장\n",
    "  with open(HISTORY_PATH, 'wb', ) as f:\n",
    "      pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7_BY_l4qi_8"
   },
   "source": [
    "# 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUgqWcoSqr3C"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = TrimapsDataset(IMAGE_PATH, MAP_PATH, test=False)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = ImprovedUNet(in_channel=3, out_channel=N_CLASSES, img_size=IMAGE_SIZE,\n",
    "                     base_ch=32, norm=\"bn\", se=True, drop=0.1, use_aspp=True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# train 함수 실행\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-28N7xkFOK9x"
   },
   "source": [
    "# 평가함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVC4S8SfOSIA"
   },
   "outputs": [],
   "source": [
    "# 평가 메트릭인 mIoU 계산 과정\n",
    "def compute_iou_tensor(pred_map, target_map):\n",
    "    intersection = (pred_map & target_map).sum(dim=(1, 2)).float()\n",
    "    union = (pred_map | target_map).sum(dim=(1, 2)).float()\n",
    "    iou = torch.where(union > 0, intersection / union, torch.ones_like(union))\n",
    "    return iou\n",
    "\n",
    "def eval(model, train_loader):\n",
    "    model.eval()\n",
    "    total_iou = torch.zeros(N_CLASSES).to(DEVICE)\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            images, targets = images.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # 클래스별 mIoU 계산\n",
    "            for cls in range(N_CLASSES):\n",
    "                pred_map = (preds == cls)\n",
    "                target_map = (targets == cls)\n",
    "\n",
    "                iou = compute_iou_tensor(pred_map, target_map)\n",
    "                total_iou[cls] += iou.sum()\n",
    "\n",
    "            total_samples += images.size(0)\n",
    "\n",
    "    mean_iou_per_class = total_iou / total_samples\n",
    "    mIoU = mean_iou_per_class.mean().item()\n",
    "\n",
    "    print(f\"[EVAL] mIoU: {mIoU:.4f}\")\n",
    "    return mIoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzTDP_ptOV2X"
   },
   "source": [
    "# 학습 데이터의 평가 결과 확인\n",
    "챌린지 결과는 테스트 데이터에서 같은 방법으로 평가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3CAQrcvOi29"
   },
   "outputs": [],
   "source": [
    "model = ImprovedUNet(3, N_CLASSES, IMAGE_SIZE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "eval(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsfNXvcJokp0"
   },
   "source": [
    "#결과 제출\n",
    "테스트 데이터에 대해 모델 수행 후 결과 파일 생성.\n",
    "\n",
    "드라이브에 저장된 submission.csv 파일을 챌린지 사이트에 제출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vv5TkY1ousl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 테스트 데이터 다운로드 & unzip\n",
    "#drive.mount('/content/drive')\n",
    "#!cp \"/content/drive/MyDrive/Colab Notebooks/project/dataset/test.zip\" /content/\n",
    "#!unzip /content/test.zip -d /content/testset\n",
    "\n",
    "# RLE (Run Length Encoding) 함수. 파일 제출 형식을 맞추기 위해 필요. 수정하지 말 것\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def get_rle(model, test_loader, save_path):\n",
    "  model.eval()\n",
    "\n",
    "  image_ids = []\n",
    "  image_paths = []\n",
    "  class_ids = []\n",
    "  rles = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, (images, data_id) in enumerate(test_loader):\n",
    "      images = images.to(DEVICE)\n",
    "\n",
    "      outputs = model(images)\n",
    "      preds = torch.argmax(outputs, dim=1)\n",
    "      preds = preds.cpu().numpy()  # numpy로 변환\n",
    "\n",
    "      for b in range(preds.shape[0]):\n",
    "          pred_mask = preds[b] + 1  # 모델에서 편의를 위해 0, 1, 2로 변환했었기 때문에 되돌리기 위해 +1\n",
    "          image_id = 'TEST_'+data_id[b]\n",
    "\n",
    "          # 클래스별 RLE 인코딩 (1=foreground, 2=border, 3=background)\n",
    "          for class_id in [1, 2, 3]:\n",
    "              mask = (pred_mask == class_id).astype(np.uint8)\n",
    "              rle = rle_encode(mask) if mask.sum() > 0 else ''\n",
    "\n",
    "              image_ids.append(image_id)\n",
    "              class_ids.append(class_id)\n",
    "              rles.append(rle)\n",
    "\n",
    "    # DataFrame 저장\n",
    "    df = pd.DataFrame({\n",
    "        'image_id': image_ids,\n",
    "        'class_id': class_ids,\n",
    "        'rle': rles\n",
    "    })\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"RLE CSV file saved : {save_path}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbDnqefkoyaF"
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "TEST_PATH = 'images'\n",
    "SUBMISSION_FILE_PATH = 'submission/submission.csv'\n",
    "\n",
    "test_set = TrimapsDataset(TEST_PATH, '', test=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = ImprovedUNet(in_channel=3, out_channel=N_CLASSES, img_size=IMAGE_SIZE,\n",
    "                     base_ch=32, norm=\"bn\", se=True, drop=0.1, use_aspp=True)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "get_rle(model, test_loader, SUBMISSION_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM6p5H1AzuCk"
   },
   "source": [
    "# [참고 활용] Loss 그래프 확인 및 Trimap 도출 결과 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNGF23Pi0Esa"
   },
   "source": [
    "Loss 그래프 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Jk7j1D10Jwy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 저장한 Loss 히스토리 로드\n",
    "with open(HISTORY_PATH, 'rb') as f:\n",
    "    model_history = pickle.load(f)\n",
    "\n",
    "# 그래프 만들어 이미지로 저장\n",
    "plt.figure()\n",
    "plt.plot(model_history['train_loss'], label='Train loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(HISTORY_PLOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로그 스케일 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# 저장한 Loss 히스토리 로드\n",
    "with open(HISTORY_PATH, 'rb') as f:\n",
    "    model_history = pickle.load(f)\n",
    "\n",
    "# 그래프 만들어 이미지로 저장\n",
    "plt.figure()\n",
    "plt.plot(model_history['train_loss'], label='Train loss')\n",
    "\n",
    "# 로그 스케일 설정\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training Loss (Log Scale)')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.savefig(HISTORY_LOGPLOT_PATH, dpi=200, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuQkVJDg0xNa"
   },
   "source": [
    "Trimap 도출 결과 확인\n",
    "\n",
    "본 코드는 학습에 사용한 이미지를 랜덤하게 선택해 확인해 보는 것으로, 테스트 이미지에 좋은 성능을 보이는지와는 일치하지 않을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8aJIGEw1Z1R"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 저장된 모델 weight 로드\n",
    "model = ImprovedUNet(in_channel=3, out_channel=N_CLASSES, img_size=IMAGE_SIZE,\n",
    "                     base_ch=32, norm=\"bn\", se=True, drop=0.1, use_aspp=True)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# 이미지 경로의 리스트 생성\n",
    "img_path_list = sorted([\n",
    "    os.path.join(IMAGE_PATH, name)\n",
    "    for name in os.listdir(IMAGE_PATH)\n",
    "    if name.endswith('.jpg')\n",
    "])\n",
    "\n",
    "# 맵 경로의 리스트 생성\n",
    "map_path_list = sorted([\n",
    "    os.path.join(MAP_PATH, name)\n",
    "    for name in os.listdir(MAP_PATH)\n",
    "    if name.endswith('.png')\n",
    "])\n",
    "\n",
    "# 랜덤한 세개의 인덱스 추출 후 이미지와 맵의 경로 저장\n",
    "indices = random.sample(range(len(img_path_list) - 1), 3)\n",
    "image_map_paths = {img_path_list[idx]: map_path_list[idx] for idx in indices}\n",
    "\n",
    "# 이미지 transform 정의. 데이터셋 클래스와 같아야 함\n",
    "transform = transforms.Compose([\n",
    "transforms.Resize(IMAGE_SIZE),\n",
    "transforms.ToTensor()\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "  figure, ax = plt.subplots(3, 3, figsize=(12, 12), subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "  for i, (image, map) in enumerate(image_map_paths.items()):\n",
    "    # 이미지 로드 후 transform. 데이터셋 클래스와 같은 작업\n",
    "    image = Image.open(image).convert('RGB')\n",
    "    image = transform(image).to(DEVICE)\n",
    "    image = torch.unsqueeze(image, dim=0) # 배치 dimension 추가\n",
    "\n",
    "    # 모델 통과 후 예측 맵 생성\n",
    "    pred = model(image).squeeze()\n",
    "    pred = torch.argmax(pred, dim=0) # logit이 가장 큰 class 선택\n",
    "    pred = pred.cpu().numpy()\n",
    "    pred = pred * 255   # 이미지로 표시하기 위해 255 곱함\n",
    "\n",
    "    # 정답 맵 로드\n",
    "    map = Image.open(map).convert('L')\n",
    "    map = transform(map)\n",
    "    map = torch.squeeze(map, dim=0)\n",
    "    map = map * 255\n",
    "    map -= 1\n",
    "\n",
    "    # 이미지 plot\n",
    "    image = image.squeeze().permute(1, 2, 0).cpu()\n",
    "    ax[i, 0].imshow(image)\n",
    "    ax[i, 1].imshow(map)\n",
    "    ax[i, 2].imshow(pred)\n",
    "\n",
    "  # Save the plot\n",
    "  figure.savefig(PRED_PLOT_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNI5I8vRcQgYQm6SSkJ+WWo",
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1VXClsnnCdNM131HqzHOP4VjIeE6e4e8Q",
     "timestamp": 1762078036850
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
